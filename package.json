{
  "name": "omnillm",
  "version": "0.0.1",
  "description": "A unified adapter layer for large language models",
  "main": "dist/cjs/index.js",
  "module": "dist/esm/index.js",
  "types": "dist/types/index.d.ts",
  "exports": {
    ".": {
      "require": "./dist/cjs/index.js",
      "import": "./dist/esm/index.mjs"
    }
  },
  "scripts": {
    "build": "npm run build:cjs && npm run build:esm && npm run build:types",
    "build:cjs": "tsc -p tsconfig.cjs.json",
    "build:esm": "tsc -p tsconfig.esm.json",
    "build:types": "tsc -p tsconfig.types.json",
    "clean": "rimraf dist",
    "test": "vitest",
    "test:cov": "vitest --coverage"
  },
  "files": [
    "dist"
  ],
  "keywords": [],
  "author": "hstar0705@gmail.com",
  "license": "MIT",
  "dependencies": {
    "@anthropic-ai/sdk": "^0.29.2",
    "@baiducloud/qianfan": "^0.1.9",
    "@google/generative-ai": "^0.21.0",
    "gpt-tokenizer": "^2.5.0",
    "openai": "^4.68.1"
  },
  "devDependencies": {
    "@types/node": "^22.7.7",
    "@types/qrcode-terminal": "^0.12.2",
    "dotenv": "^16.4.5",
    "rimraf": "^6.0.1",
    "typescript": "^5.6.3",
    "vitest": "^2.1.3",
    "wechaty": "^1.20.2",
    "wechaty-puppet-wechat4u": "^1.14.14",
    "qrcode-terminal": "^0.12.0"
  }
}
